{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84330ea7",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this challenge, we aim to predict the active power signal of a wind turbine using 10-minute SCADA data from neighbouring turbines. The code for all my submissions can be found [here](https://github.com/davidbossanyi/hill-of-towie-wind-turbine-power-prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b965cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment these lines out when developing locally\n",
    "! pip install ephem 'flaml[automl]'\n",
    "%cd /kaggle/working\n",
    "\n",
    "# set the time budget per fit (recommend 180s locally, 240s on Kaggle)\n",
    "time_budget = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import ephem\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import requests\n",
    "from flaml.automl import AutoML\n",
    "from kagglehub.config import DEFAULT_CACHE_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SunPosition:\n",
    "    def __init__(self, *, latitude: float, longitude: float) -> None:\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "        self._observer = self._create_ephem_observer()\n",
    "        self._sun = ephem.Sun()\n",
    "\n",
    "    def _create_ephem_observer(self) -> ephem.Observer:\n",
    "        observer = ephem.Observer()\n",
    "        observer.lat = str(self.latitude)\n",
    "        observer.lon = str(self.longitude)\n",
    "        return observer\n",
    "\n",
    "    def altitude(self, *, timestamp_utc: dt.datetime) -> float:\n",
    "        self._observer.date = timestamp_utc\n",
    "        self._sun.compute(self._observer)\n",
    "        return self._sun.alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cfb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = Path(DEFAULT_CACHE_FOLDER) / \"competitions\" / \"hill-of-towie-wind-turbine-power-prediction\"\n",
    "\n",
    "\n",
    "def load_training_dataset(*, force_download: bool = False) -> pl.LazyFrame:\n",
    "    file_path = kagglehub.competition_download(\n",
    "        handle=\"hill-of-towie-wind-turbine-power-prediction\",\n",
    "        path=\"training_dataset.parquet\",\n",
    "        force_download=force_download,\n",
    "    )\n",
    "    return pl.scan_parquet(Path(file_path))\n",
    "\n",
    "\n",
    "def load_submission_dataset(*, force_download: bool = False) -> pl.LazyFrame:\n",
    "    file_path = kagglehub.competition_download(\n",
    "        handle=\"hill-of-towie-wind-turbine-power-prediction\",\n",
    "        path=\"submission_dataset.parquet\",\n",
    "        force_download=force_download,\n",
    "    )\n",
    "    return pl.scan_parquet(Path(file_path))\n",
    "\n",
    "\n",
    "def load_turbine_metadata(*, force_download: bool = False) -> pl.LazyFrame:\n",
    "    file_path = CACHE_DIR / \"turbine_metadata.csv\"\n",
    "    if not file_path.exists() or force_download:\n",
    "        response = requests.get(\n",
    "            \"https://zenodo.org/records/14870023/files/Hill_of_Towie_turbine_metadata.csv?download=1\",\n",
    "            headers={\"Accept\": \"text/csv\"},\n",
    "            timeout=10,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        file_path.write_text(response.content.decode(\"utf-8-sig\"), encoding=\"utf-8\")\n",
    "    return pl.scan_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13420466",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "#### Load the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_training_dataset().collect()\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d41884",
   "metadata": {},
   "source": [
    "#### Basic feature engineering and selection\n",
    "I have deliberately chosen to keep only features derived from the wind turbine SCADA data, since other sources such as ERA5 may not be accessible in real time at a real wind farm.\n",
    "\n",
    "The data is preprocessed and filtered as follows:\n",
    " - Create an \"age of data\" feature that counts the number of seconds since 2016\n",
    " - Choose yaw position over nacelle position (same information) as a proxy for local wind direction and calculate its `sin` and `cos` since it is a circular variable, and the data spans more than 360 degrees\n",
    " - Take the mean of the reference wind turbine ambient temperatures as a single feature, since the data is very similar across turbines\n",
    " - Include the 10-minute lagged wind speed and active power as features, since the partial autocorrelation is fairly strong with a lag of 10 minutes\n",
    " - Include sinusoidal time features (hour of day, day of year, month of year) to capture daily and seasonal patterns\n",
    " - Include the altitude of the sun as a feature, as a very rough proxy for atmospheric stability\n",
    " - Filter on the `is_valid` column - we can't hope to predict turbine faults or missing data, and in any case, the Kaggle scoring excludes invalid rows\n",
    "\n",
    "We retain only the following features:\n",
    " - wind speed (mean, min, max, std, 10-min lag of mean) for all reference turbines\n",
    " - active power (mean, min, max, std, 10-min lag of mean) for all reference turbines\n",
    " - sin and cos of mean yaw position for all reference turbines, and the yaw position std\n",
    " - time in operation for all reference turbines (the model needs to know which turbines are offline so it can learn waking scenarios)\n",
    " - generator rpm for all reference turbines\n",
    " - pitch position (just blade A to reduce feature redundancy) for all reference turbines\n",
    " - mean ambient temperature, as described above\n",
    " - sin and cos of time features, as described above\n",
    " - altitude of the sun (as described above)\n",
    " - age of data (as described above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X: pl.DataFrame, *, ref_wtgs: list[int], lat: float, lon: float) -> pl.DataFrame:\n",
    "    sun_position = SunPosition(latitude=lat, longitude=lon)\n",
    "    X = (\n",
    "        X.lazy()\n",
    "        .with_columns(\n",
    "            pl.col(\"TimeStamp_StartFormat\")\n",
    "            .sub(dt.datetime(2016, 1, 1, tzinfo=dt.UTC))\n",
    "            .dt.total_seconds()\n",
    "            .alias(\"seconds_since_2016\"),\n",
    "            *[\n",
    "                pl.col(f\"wtc_ScYawPos_mean;{wtg}\").radians().sin().alias(f\"wtc_ScYawPos_mean_sin;{wtg}\")\n",
    "                for wtg in ref_wtgs\n",
    "            ],\n",
    "            *[\n",
    "                pl.col(f\"wtc_ScYawPos_mean;{wtg}\").radians().cos().alias(f\"wtc_ScYawPos_mean_cos;{wtg}\")\n",
    "                for wtg in ref_wtgs\n",
    "            ],\n",
    "            pl.concat_list([pl.col(f\"wtc_AmbieTmp_mean;{wtg}\") for wtg in ref_wtgs])\n",
    "            .list.mean()\n",
    "            .alias(\"ambient_temp_mean\"),\n",
    "        )\n",
    "        .collect()\n",
    "    )\n",
    "    return (\n",
    "        X.lazy()\n",
    "        .with_columns(\n",
    "            *[\n",
    "                pl.col(col).shift(1).alias(col + \"_lag10min\")\n",
    "                for col in X.columns\n",
    "                if col not in [\"TimeStamp_StartFormat\", \"is_valid\", \"seconds_since_2016\"]\n",
    "            ]\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"TimeStamp_StartFormat\").dt.minute().mul(2 * math.pi / 60).sin().alias(\"minutes_sin\"),\n",
    "            pl.col(\"TimeStamp_StartFormat\").dt.minute().mul(2 * math.pi / 60).cos().alias(\"minutes_cos\"),\n",
    "            pl.col(\"TimeStamp_StartFormat\").dt.hour().mul(2 * math.pi / 24).sin().alias(\"hours_sin\"),\n",
    "            pl.col(\"TimeStamp_StartFormat\").dt.hour().mul(2 * math.pi / 24).cos().alias(\"hours_cos\"),\n",
    "            pl.col(\"TimeStamp_StartFormat\").dt.ordinal_day().mul(2 * math.pi / 365).sin().alias(\"days_sin\"),\n",
    "            pl.col(\"TimeStamp_StartFormat\").dt.ordinal_day().mul(2 * math.pi / 365).cos().alias(\"days_cos\"),\n",
    "            pl.col(\"TimeStamp_StartFormat\").dt.month().mul(2 * math.pi / 12).sin().alias(\"months_sin\"),\n",
    "            pl.col(\"TimeStamp_StartFormat\").dt.month().mul(2 * math.pi / 12).cos().alias(\"months_cos\"),\n",
    "        )\n",
    "        .collect()\n",
    "        .with_columns(\n",
    "            pl.col(\"TimeStamp_StartFormat\")\n",
    "            .map_elements(lambda ts: sun_position.altitude(timestamp_utc=ts), return_dtype=pl.Float64)\n",
    "            .mul(180 / math.pi)\n",
    "            .alias(\"sun_altitude\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_is_valid(X: pl.DataFrame, y: pl.Series) -> tuple[pl.DataFrame, pl.Series]:\n",
    "    y = y.filter(X.select(\"is_valid\").to_series())\n",
    "    X = X.filter(pl.col(\"is_valid\"))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def select_features(X: pl.DataFrame, *, ref_wtgs: list[int]) -> pl.DataFrame:\n",
    "    cols = [\n",
    "        *[pl.col(f\"wtc_AcWindSp_mean;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_AcWindSp_stddev;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_AcWindSp_min;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_AcWindSp_max;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_ScYawPos_mean_sin;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_ScYawPos_mean_cos;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_ScYawPos_stddev;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_ScReToOp_timeon;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_ActPower_mean;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_ActPower_stddev;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_ActPower_min;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_ActPower_max;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_GenRpm_mean;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_PitcPosA_mean;{ref_wtg}\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_AcWindSp_mean;{ref_wtg}_lag10min\") for ref_wtg in ref_wtgs],\n",
    "        *[pl.col(f\"wtc_ActPower_mean;{ref_wtg}_lag10min\") for ref_wtg in ref_wtgs],\n",
    "        pl.col(\"ambient_temp_mean\"),\n",
    "        pl.col(\"sun_altitude\"),\n",
    "        pl.col(\"seconds_since_2016\"),\n",
    "        pl.col(\"hours_sin\"),\n",
    "        pl.col(\"hours_cos\"),\n",
    "        pl.col(\"days_sin\"),\n",
    "        pl.col(\"days_cos\"),\n",
    "        pl.col(\"months_sin\"),\n",
    "        pl.col(\"months_cos\"),\n",
    "    ]\n",
    "    return X.select(*cols)\n",
    "\n",
    "\n",
    "def plot_generalization(\n",
    "    automl: AutoML,\n",
    "    *,\n",
    "    X_train: pl.DataFrame,\n",
    "    y_train: pl.Series,\n",
    "    X_validation: pl.DataFrame,\n",
    "    y_validation: pl.Series,\n",
    "    variable_name: str,\n",
    "    unit: str,\n",
    ") -> None:\n",
    "    train_prediction = pl.Series(values=automl.predict(X_train.to_pandas()))\n",
    "    validation_prediction = pl.Series(values=automl.predict(X_validation.to_pandas()))\n",
    "    mae_train = abs(y_train - train_prediction).mean()\n",
    "    mae_validation = abs(y_validation - validation_prediction).mean()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    ax1.scatter(\n",
    "        x=y_train.to_numpy().flatten(),\n",
    "        y=train_prediction.to_numpy().flatten(),\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    ax1.text(0.05, 0.95, f\"MAE: {mae_train:.2f} {unit}\", ha=\"left\", va=\"top\", transform=ax1.transAxes)\n",
    "    ax1.set_xlabel(f\"True {variable_name} [{unit}]\")\n",
    "    ax1.set_ylabel(f\"Predicted {variable_name} [{unit}]\")\n",
    "    ax1.set_title(\"Training set\")\n",
    "    ax1.grid(visible=True)\n",
    "\n",
    "    ax2.scatter(\n",
    "        x=y_validation.to_numpy().flatten(),\n",
    "        y=validation_prediction.to_numpy().flatten(),\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    ax2.text(0.05, 0.95, f\"MAE: {mae_validation:.2f} {unit}\", ha=\"left\", va=\"top\", transform=ax2.transAxes)\n",
    "    ax2.set_xlabel(f\"True Wind {variable_name} [{unit}]\")\n",
    "    ax2.set_ylabel(f\"Predicted {variable_name} [{unit}]\")\n",
    "    ax2.set_title(\"Validation set\")\n",
    "    ax2.grid(visible=True)\n",
    "\n",
    "\n",
    "def plot_feature_importance(automl: AutoML) -> None:\n",
    "    feature_importance = pl.DataFrame(\n",
    "        {\n",
    "            \"Name\": automl.feature_names_in_,\n",
    "            \"Importance\": automl.feature_importances_,\n",
    "        },\n",
    "    ).sort(\"Importance\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.17 * len(feature_importance)))\n",
    "    bars = ax.barh(\n",
    "        y=feature_importance.select(\"Name\").to_numpy().flatten(),\n",
    "        width=feature_importance.select(\"Importance\").to_numpy().flatten(),\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.bar_label(bars)\n",
    "    ax.set_xlabel(\"Importance\")\n",
    "    ax.set_ylabel(\"Feature\")\n",
    "    ax.set_ylim(0.1, len(feature_importance))\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25541c",
   "metadata": {},
   "source": [
    "#### Model the wind speed\n",
    "\n",
    "Wind speed is a key driver of active power output of a turbine. Therefore, we begin by modelling the wind speed of the target turbine, using only the features listed above.\n",
    "\n",
    "The challenge aims to predict a year of data using historical data. Therefore, we take the last year of the training set as a validation set, and train the model in the remaining three years to start with. We use `XGBoost` since it can handle complex data with large numbers of features reasonably well. Hyperparameters are tuned using cross-fold validation and uniform splitting to maximise generalisation performance. Later, during retraining, we use time-aware splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf87dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ws = df_train.select(pl.exclude(\"wtc_AcWindSp_mean;1\"))\n",
    "y_train_ws = df_train.select(\"wtc_AcWindSp_mean;1\").to_series()\n",
    "\n",
    "X_test = load_submission_dataset().collect()\n",
    "\n",
    "wf_lat_lon = load_turbine_metadata().select(pl.col(\"Latitude\").mean(), pl.col(\"Longitude\").mean()).collect()\n",
    "\n",
    "training_mask = X_train_ws.select(\n",
    "    pl.col(\"TimeStamp_StartFormat\").lt(dt.datetime(2019, 1, 1, tzinfo=dt.UTC))\n",
    ").to_series()\n",
    "X_validation_ws = X_train_ws.filter(~training_mask)\n",
    "y_validation_ws = y_train_ws.filter(~training_mask)\n",
    "X_train_ws = X_train_ws.filter(training_mask)\n",
    "y_train_ws = y_train_ws.filter(training_mask)\n",
    "\n",
    "X_train_ws = preprocess(\n",
    "    X_train_ws,\n",
    "    ref_wtgs=[2, 3, 4, 5, 7],\n",
    "    lat=wf_lat_lon.select(\"Latitude\").item(),\n",
    "    lon=wf_lat_lon.select(\"Longitude\").item(),\n",
    ")\n",
    "\n",
    "X_train_ws, y_train_ws = filter_is_valid(X_train_ws, y_train_ws)\n",
    "X_train_ws = select_features(X_train_ws, ref_wtgs=[2, 3, 4, 5, 7])\n",
    "\n",
    "X_validation_ws = preprocess(\n",
    "    X_validation_ws,\n",
    "    ref_wtgs=[2, 3, 4, 5, 7],\n",
    "    lat=wf_lat_lon.select(\"Latitude\").item(),\n",
    "    lon=wf_lat_lon.select(\"Longitude\").item(),\n",
    ")\n",
    "\n",
    "X_validation_ws, y_validation_ws = filter_is_valid(X_validation_ws, y_validation_ws)\n",
    "X_validation_ws = select_features(X_validation_ws, ref_wtgs=[2, 3, 4, 5, 7])\n",
    "\n",
    "automl_ws = AutoML()\n",
    "automl_settings = {\n",
    "    \"time_budget\": time_budget,\n",
    "    \"task\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"estimator_list\": [\n",
    "        \"xgboost\",\n",
    "    ],\n",
    "    \"log_file_name\": \"automl.log\",\n",
    "    \"seed\": 42,\n",
    "    \"eval_method\": \"cv\",\n",
    "    \"n_splits\": 5,\n",
    "    \"split_type\": \"uniform\",\n",
    "    \"early_stop\": True,\n",
    "}\n",
    "automl_ws.fit(\n",
    "    X_train=X_train_ws.to_pandas(),\n",
    "    y_train=y_train_ws.to_pandas(),\n",
    "    **automl_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67797a7b",
   "metadata": {},
   "source": [
    "##### Assess generalisation\n",
    "\n",
    "The MAEs obtained for wind speed are similar to the best entries in the [Kaggle competition to predict wind speed](https://www.kaggle.com/competitions/predict-the-wind-speed-at-a-wind-turbine). The model appears to generalise well; the scores for training and validation sets are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_generalization(\n",
    "    automl_ws,\n",
    "    X_train=X_train_ws,\n",
    "    y_train=y_train_ws,\n",
    "    X_validation=X_validation_ws,\n",
    "    y_validation=y_validation_ws,\n",
    "    variable_name=\"Wind Speed\",\n",
    "    unit=\"m/s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc4607",
   "metadata": {},
   "source": [
    "##### Plot feature importance\n",
    "\n",
    "As expected, wind speed and active power signals tend to dominate the feature importance. Yaw position and time in operation, while small, are crucial for modelling wake effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155bf044",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(automl_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549cad43",
   "metadata": {},
   "source": [
    "##### Refit to the full training dataset\n",
    "\n",
    "Finally, we refit the wind speed model to the full training dataset, again using cross-fold validation to ensure generalisation performance, but now using time-aware splitting to ensure that the model is trained on data that is always earlier than the validation set. The hyperparameters from the previous model are used as the startging point for the refitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_ws_full = AutoML()\n",
    "automl_settings = {\n",
    "    \"time_budget\": time_budget,\n",
    "    \"task\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"estimator_list\": [\n",
    "        \"xgboost\",\n",
    "    ],\n",
    "    \"log_file_name\": \"automl.log\",\n",
    "    \"seed\": 42,\n",
    "    \"eval_method\": \"cv\",\n",
    "    \"n_splits\": 5,\n",
    "    \"split_type\": \"time\",\n",
    "    \"early_stop\": True,\n",
    "    \"starting_points\": automl_ws.best_config_per_estimator,\n",
    "}\n",
    "automl_ws_full.fit(\n",
    "    X_train=pl.concat([X_train_ws, X_validation_ws]).to_pandas(),\n",
    "    y_train=pl.concat([y_train_ws, y_validation_ws]).to_pandas(),\n",
    "    **automl_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = pl.Series(values=automl_ws_full.predict(pl.concat([X_train_ws, X_validation_ws]).to_pandas()))\n",
    "mae_train = abs(pl.concat([y_train_ws, y_validation_ws]) - train_prediction).mean()\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "ax1.scatter(\n",
    "    x=pl.concat([y_train_ws, y_validation_ws]).to_numpy().flatten(),\n",
    "    y=train_prediction.to_numpy().flatten(),\n",
    "    alpha=0.1,\n",
    ")\n",
    "ax1.text(0.05, 0.95, f\"MAE: {mae_train:.2f}\", ha=\"left\", va=\"top\", transform=ax1.transAxes)\n",
    "ax1.set_xlabel(\"True\")\n",
    "ax1.set_ylabel(\"Predicted\")\n",
    "ax1.set_title(\"Full Train set\")\n",
    "ax1.grid(visible=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ab546",
   "metadata": {},
   "source": [
    "#### Predict the power\n",
    "\n",
    "Finally, we repeat essentially the same process for the active power signal, adding in the modelled wind speed as an additional feature. Again, we first split the training set into the same training and validation sets, assess the generalisation performance, plot the feature importance, and then refit to the full training dataset using time-aware splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.select(pl.exclude(\"target\"))\n",
    "y_train = df_train.select(\"target\").to_series()\n",
    "\n",
    "X_test = load_submission_dataset().collect()\n",
    "\n",
    "wf_lat_lon = load_turbine_metadata().select(pl.col(\"Latitude\").mean(), pl.col(\"Longitude\").mean()).collect()\n",
    "\n",
    "training_mask = X_train.select(pl.col(\"TimeStamp_StartFormat\").lt(dt.datetime(2019, 1, 1, tzinfo=dt.UTC))).to_series()\n",
    "X_validation = X_train.filter(~training_mask)\n",
    "y_validation = y_train.filter(~training_mask)\n",
    "X_train = X_train.filter(training_mask)\n",
    "y_train = y_train.filter(training_mask)\n",
    "\n",
    "X_train = preprocess(\n",
    "    X_train,\n",
    "    ref_wtgs=[2, 3, 4, 5, 7],\n",
    "    lat=wf_lat_lon.select(\"Latitude\").item(),\n",
    "    lon=wf_lat_lon.select(\"Longitude\").item(),\n",
    ")\n",
    "\n",
    "X_train, y_train = filter_is_valid(X_train, y_train)\n",
    "X_train = select_features(X_train, ref_wtgs=[2, 3, 4, 5, 7])\n",
    "\n",
    "assert len([col for col in X_train.columns if col.endswith(\";1\")]) == 0, (\n",
    "    \"Test turbine features should not be in training set\"\n",
    ")\n",
    "\n",
    "X_validation = preprocess(\n",
    "    X_validation,\n",
    "    ref_wtgs=[2, 3, 4, 5, 7],\n",
    "    lat=wf_lat_lon.select(\"Latitude\").item(),\n",
    "    lon=wf_lat_lon.select(\"Longitude\").item(),\n",
    ")\n",
    "\n",
    "X_validation, y_validation = filter_is_valid(X_validation, y_validation)\n",
    "X_validation = select_features(X_validation, ref_wtgs=[2, 3, 4, 5, 7])\n",
    "\n",
    "X_train = X_train.with_columns(engineered_wind_speed=pl.Series(values=automl_ws_full.predict(X_train.to_pandas())))\n",
    "X_validation = X_validation.with_columns(\n",
    "    engineered_wind_speed=pl.Series(values=automl_ws_full.predict(X_validation.to_pandas()))\n",
    ")\n",
    "\n",
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "    \"time_budget\": time_budget,\n",
    "    \"task\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"estimator_list\": [\n",
    "        \"xgboost\",\n",
    "    ],\n",
    "    \"log_file_name\": \"automl.log\",\n",
    "    \"seed\": 42,\n",
    "    \"eval_method\": \"cv\",\n",
    "    \"n_splits\": 5,\n",
    "    \"split_type\": \"uniform\",\n",
    "    \"early_stop\": True,\n",
    "}\n",
    "automl.fit(\n",
    "    X_train=X_train.to_pandas(),\n",
    "    y_train=y_train.to_pandas(),\n",
    "    **automl_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f8ec0",
   "metadata": {},
   "source": [
    "##### Assess generalisation\n",
    "\n",
    "The model overfits slightly; in particular there are a few outliers at low power values (100-300kW) that need investigating. But overall the generalisation is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ffb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_generalization(\n",
    "    automl,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_validation=X_validation,\n",
    "    y_validation=y_validation,\n",
    "    variable_name=\"Active Power\",\n",
    "    unit=\"kW\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411f996",
   "metadata": {},
   "source": [
    "##### Plot feature importance\n",
    "\n",
    "As expected the engineered wind speed feature is the most important, followed by active power and wind speed signals from the reference turbines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(automl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de31d4c",
   "metadata": {},
   "source": [
    "##### Refit to the full training dataset\n",
    "\n",
    "This follows the same process as for the wind speed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_full = AutoML()\n",
    "automl_settings = {\n",
    "    \"time_budget\": time_budget,\n",
    "    \"task\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"estimator_list\": [\n",
    "        \"xgboost\",\n",
    "    ],\n",
    "    \"log_file_name\": \"automl.log\",\n",
    "    \"seed\": 42,\n",
    "    \"eval_method\": \"cv\",\n",
    "    \"n_splits\": 5,\n",
    "    \"split_type\": \"time\",\n",
    "    \"early_stop\": True,\n",
    "    \"starting_points\": automl.best_config_per_estimator,\n",
    "}\n",
    "automl_full.fit(\n",
    "    X_train=pl.concat([X_train, X_validation]).to_pandas(),\n",
    "    y_train=pl.concat([y_train, y_validation]).to_pandas(),\n",
    "    **automl_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = pl.Series(values=automl_full.predict(pl.concat([X_train, X_validation]).to_pandas()))\n",
    "mae_train = abs(pl.concat([y_train, y_validation]) - train_prediction).mean()\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "ax1.scatter(\n",
    "    x=pl.concat([y_train, y_validation]).to_numpy().flatten(),\n",
    "    y=train_prediction.to_numpy().flatten(),\n",
    "    alpha=0.1,\n",
    ")\n",
    "ax1.text(0.05, 0.95, f\"MAE: {mae_train:.2f} kW\", ha=\"left\", va=\"top\", transform=ax1.transAxes)\n",
    "ax1.set_xlabel(\"True Active Power [kW]\")\n",
    "ax1.set_ylabel(\"Predicted Active Power [kW]\")\n",
    "ax1.set_title(\"Full Train set\")\n",
    "ax1.grid(visible=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f09aed0",
   "metadata": {},
   "source": [
    "### Generate predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_submission_dataset().collect()\n",
    "df_id = X_test.select(\"id\")\n",
    "\n",
    "X_test = preprocess(\n",
    "    X_test,\n",
    "    ref_wtgs=[2, 3, 4, 5, 7],\n",
    "    lat=wf_lat_lon.select(\"Latitude\").item(),\n",
    "    lon=wf_lat_lon.select(\"Longitude\").item(),\n",
    ")\n",
    "\n",
    "X_test = select_features(X_test, ref_wtgs=[2, 3, 4, 5, 7])\n",
    "\n",
    "X_test = X_test.with_columns(engineered_wind_speed=pl.Series(values=automl_ws_full.predict(X_test.to_pandas())))\n",
    "y_test = pl.Series(values=automl_full.predict(X_test.to_pandas()))\n",
    "\n",
    "submission = df_id.with_columns(prediction=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb267933",
   "metadata": {},
   "source": [
    "### Check and save the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the columns are the expected ones\n",
    "assert submission.columns == [\"id\", \"prediction\"], f'Expected columns [\"id\", \"prediction\"], found: {submission.columns}'\n",
    "\n",
    "# checking no nulls in the data\n",
    "assert submission.select(pl.col(\"id\").is_null().sum()).item() == 0, \"There are null values in the 'id' column\"\n",
    "assert submission.select(pl.col(\"id\").is_nan().sum()).item() == 0, \"There are nan values in the 'id' column\"\n",
    "assert submission.select(pl.col(\"prediction\").is_null().sum()).item() == 0, (\n",
    "    \"There are null values in the 'prediction' column\"\n",
    ")\n",
    "assert submission.select(pl.col(\"prediction\").is_nan().sum()).item() == 0, (\n",
    "    \"There are nan values in the 'prediction' column\"\n",
    ")\n",
    "\n",
    "# checking the row ids are unique and within expected range\n",
    "duplicated_ids = submission.select(\"id\").is_duplicated()\n",
    "assert not duplicated_ids.any(), (\n",
    "    f\"There are duplicated ids: {submission.select('id').filter(duplicated_ids).to_series().unique()}\"\n",
    ")\n",
    "invalid_ids = set(submission.select(\"id\").unique().to_series().to_list()) - set(range(52704))\n",
    "assert not invalid_ids, f\"The following row IDs are not within the expected ones: {invalid_ids}\"\n",
    "\n",
    "print(\"Submission file is valid and ready for submission.\")\n",
    "\n",
    "submission.write_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
